# -*- coding: utf-8 -*-
"""covid19_sentiment_analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xnibCTi4EVfEIvdb8jr8HQUD-RTTTvcJ
"""

import tweepy
import pandas as pd
import re
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
import matplotlib.pyplot as plt
from wordcloud import WordCloud

# Twitter API credentials (fill in with your own credentials)
API_KEY = 'your_api_key'
API_SECRET = 'your_api_secret'
ACCESS_TOKEN = 'your_access_token'
ACCESS_TOKEN_SECRET = 'your_access_token_secret'

# Set up tweepy client
auth = tweepy.OAuthHandler(API_KEY, API_SECRET)
auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)
api = tweepy.API(auth, wait_on_rate_limit=True)

# Function to collect tweets based on keywords and date range
def collect_tweets(keywords, since_date, until_date, max_tweets=1000):
    tweets = []
    for tweet in tweepy.Cursor(api.search_tweets,
                               q=keywords,
                               lang="en",
                               since=since_date,
                               until=until_date,
                               tweet_mode='extended').items(max_tweets):
        tweets.append([tweet.full_text, tweet.user.location])
    return pd.DataFrame(tweets, columns=['Text', 'Location'])

# Example keywords and date range
keywords = "#COVID19 OR #vaccine OR Moderna OR Pfizer OR Sinopharm OR Covaxin"
since_date = "2021-01-01"
until_date = "2021-12-31"

# Collect tweets
tweets_df = collect_tweets(keywords, since_date, until_date, max_tweets=2000)

# Preprocessing function
def preprocess_text(text):
    text = text.lower()
    text = re.sub(r"http\S+", "", text)
    text = re.sub(r"@\w+", "", text)
    text = re.sub(r"#", "", text)
    text = re.sub(r"[^\w\s]", "", text)
    return text

# Apply preprocessing
tweets_df['Cleaned_Text'] = tweets_df['Text'].apply(preprocess_text)

# Sentiment Analysis using VADER
analyzer = SentimentIntensityAnalyzer()

def analyze_sentiment(text):
    score = analyzer.polarity_scores(text)['compound']
    if score >= 0.05:
        return 'Positive'
    elif score <= -0.05:
        return 'Negative'
    else:
        return 'Neutral'

tweets_df['Sentiment'] = tweets_df['Cleaned_Text'].apply(analyze_sentiment)

# Summary of sentiment analysis
sentiment_summary = tweets_df['Sentiment'].value_counts(normalize=True) * 100
print(sentiment_summary)

# Visualizing Sentiments as a Pie Chart
plt.figure(figsize=(8, 6))
tweets_df['Sentiment'].value_counts().plot.pie(autopct='%1.1f%%', colors=['#66b3ff','#99ff99','#ffcc99'])
plt.title("Overall Sentiment Distribution")
plt.ylabel('')
plt.show()

# Word Cloud for Each Sentiment
for sentiment in ['Positive', 'Negative', 'Neutral']:
    text = " ".join(review for review in tweets_df[tweets_df['Sentiment'] == sentiment].Cleaned_Text)
    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)
    plt.figure(figsize=(10, 5))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.title(f"Word Cloud for {sentiment} Sentiments")
    plt.axis("off")
    plt.show()

# Temporal Analysis: Sentiments over Time
tweets_df['Date'] = pd.to_datetime(tweets_df.index)  # Use tweet timestamp if available
tweets_df.set_index('Date', inplace=True)
daily_sentiment = tweets_df.resample('D').apply(lambda x: x['Sentiment'].value_counts(normalize=True) * 100)

# Plotting Daily Sentiment Trends
plt.figure(figsize=(14, 7))
for sentiment in ['Positive', 'Negative', 'Neutral']:
    plt.plot(daily_sentiment.index, daily_sentiment[sentiment], label=sentiment)
plt.title('Daily Sentiment Trend Over Time')
plt.xlabel('Date')
plt.ylabel('Percentage')
plt.legend()
plt.show()

# Geographical Analysis: Sentiment Distribution by Country
# Here, we are assuming 'Location' holds country data, ideally, you would preprocess it to ensure consistency
location_sentiment = tweets_df.groupby('Location')['Sentiment'].value_counts(normalize=True).unstack().fillna(0)

# Display top locations with most tweets
top_locations = location_sentiment.nlargest(10, 'Positive')
top_locations.plot(kind='bar', stacked=True, figsize=(12, 6), color=['#66b3ff','#99ff99','#ffcc99'])
plt.title('Sentiment Distribution by Location (Top 10)')
plt.xlabel('Location')
plt.ylabel('Proportion of Sentiment')
plt.legend(title="Sentiment")
plt.show()